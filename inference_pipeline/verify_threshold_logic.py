#!/usr/bin/env python3
"""
Verification script to demonstrate the threshold/scoring logic issue
"""

import yaml

def load_thresholds():
    """Load thresholds from config.yaml"""
    try:
        with open('config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        return config['inference']['thresholds']
    except:
        # Fallback values from the config file
        return {
            'damage': 0.50,
            'occlusion': 0.40,
            'crop': 0.49
        }

def test_threshold_logic():
    """Test the threshold logic for all classes"""
    thresholds = load_thresholds()
    
    print("=" * 60)
    print("THRESHOLD AND SCORING LOGIC VERIFICATION")
    print("=" * 60)
    
    # Test probabilities
    test_probs = [0.1, 0.2, 0.3, 0.35, 0.39, 0.40, 0.45, 0.49, 0.50, 0.55, 0.75, 0.85, 0.95]
    
    for class_name, threshold in thresholds.items():
        print(f"\nüìä {class_name.upper()} DETECTION (threshold = {threshold})")
        print("-" * 50)
        
        low_conf_possible = False
        low_conf_examples = []
        
        for prob in test_probs:
            prediction = prob >= threshold
            can_have_low_conf_penalty = prediction and prob < 0.5
            
            if can_have_low_conf_penalty:
                low_conf_possible = True
                low_conf_examples.append(prob)
            
            if prediction:  # Only show cases where penalty would be applied
                if prob > 0.8:
                    conf_level = "HIGH"
                    penalty = {"damage": 50, "occlusion": 20, "crop": 15}[class_name]
                elif prob > 0.5:
                    conf_level = "MEDIUM"  
                    penalty = {"damage": 30, "occlusion": 12, "crop": 8}[class_name]
                else:
                    conf_level = "LOW"
                    penalty = {"damage": 15, "occlusion": 5, "crop": 3}[class_name]
                
                print(f"  Prob: {prob:4.2f} ‚Üí Prediction: True  ‚Üí Confidence: {conf_level:6} ‚Üí Penalty: -{penalty:2d} pts")
        
        # Summary
        if low_conf_possible:
            print(f"\n‚úÖ 'Low Confidence + Prediction=True' IS POSSIBLE")
            print(f"   Examples: {low_conf_examples}")
        else:
            print(f"\n‚ùå 'Low Confidence + Prediction=True' IS **IMPOSSIBLE**")
            print(f"   Reason: All probabilities ‚â• {threshold} are also ‚â• 0.5")

def analyze_paper_claims():
    """Analyze the claims in the paper about low confidence penalties"""
    print("\n" + "=" * 60)  
    print("PAPER CLAIMS ANALYSIS")
    print("=" * 60)
    
    claims = {
        "damage": "Low Confidence (<0.5, prediction=true): -15 points",
        "occlusion": "Low Confidence (<0.5, prediction=true): -5 points", 
        "crop": "Low Confidence (<0.5, prediction=true): -3 points"
    }
    
    thresholds = load_thresholds()
    
    for class_name, claim in claims.items():
        threshold = thresholds[class_name]
        is_possible = threshold < 0.5
        
        print(f"\nüìù {class_name.upper()}: {claim}")
        print(f"   Threshold: {threshold}")
        print(f"   Status: {'‚úÖ VALID' if is_possible else '‚ùå INVALID - IMPOSSIBLE'}")
        
        if not is_possible:
            print(f"   Problem: No probability can be both ‚â•{threshold} (for prediction=True) AND <0.5")

def recommend_fixes():
    """Provide recommendations to fix the issue"""
    print("\n" + "=" * 60)
    print("RECOMMENDED FIXES")
    print("=" * 60)
    
    print("""
üîß OPTION 1: Fix the Paper (Recommended)
   Remove "Low Confidence" penalty for damage detection since it's impossible.
   
   Damage Detection Penalties:
   ‚Ä¢ High Confidence (>0.8): -50 points
   ‚Ä¢ Medium Confidence (0.5-0.8): -30 points
   ‚Ä¢ [REMOVE] Low Confidence (<0.5, prediction=true): -15 points

üîß OPTION 2: Adjust Damage Threshold
   Change damage threshold to 0.3 to enable "low confidence" penalties:
   
   inference:
     thresholds:
       damage: 0.30  # Allows 0.30-0.49 range for "low confidence"
       occlusion: 0.40
       crop: 0.49

üîß OPTION 3: Redefine Confidence Levels
   Rename categories to avoid confusion:
   ‚Ä¢ Strong Confidence (>0.8)
   ‚Ä¢ Moderate Confidence (threshold to 0.8)  
   ‚Ä¢ [No penalty for below threshold since prediction=False]
   """)

if __name__ == "__main__":
    test_threshold_logic()
    analyze_paper_claims()
    recommend_fixes()

